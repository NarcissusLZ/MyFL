import os
import glob
import pandas as pd
import numpy as np
import csv
import multiprocessing
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm

# === è·¯å¾„é…ç½® ===
DATASET_ROOT = './datasets/opt'
OUTPUT_CSV = './datasets/iot23.csv'

# === é‡‡æ ·é…é¢ ===
# å»ºè®®ä¿æŒ 20ä¸‡ï¼Œè¶³å¤Ÿè®­ç»ƒä¸”é€Ÿåº¦å¿«
MAX_SAMPLES_PER_CLASS = 50000

# === æ˜ å°„è¡¨ ===
LABEL_MAP = {
    'benign': 0, 'ddos': 1, 'portscan': 2, 'c&c': 3,
    'attack': 4, 'malware': 4, 'okiru': 4, 'malicious': 4, 'virus': 4
}
PROTO_MAP = {'tcp': 0, 'udp': 1, 'icmp': 2, 'ipv6-icmp': 3, 'igmp': 4, 'arp': 5}
STATE_MAP = {'S0': 0, 'S1': 1, 'SF': 2, 'REJ': 3, 'S2': 4, 'S3': 5, 'RSTO': 6, 'RSTR': 7, 'RSTOS0': 8, 'RSTRH': 9,
             'SH': 10, 'SHR': 11, 'OTH': 12}

FEATURE_COLS = [
    'duration', 'orig_bytes', 'resp_bytes', 'missed_bytes',
    'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes',
    'proto', 'conn_state'
]
# æˆ‘ä»¬ä¾ç„¶å®šä¹‰è¿™äº›åˆ—åï¼Œä¸»è¦æ˜¯ä¸ºäº†è®©å‰é¢çš„ç‰¹å¾åˆ—å¯¹é½
COL_NAMES_23 = [
    'ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p',
    'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes',
    'conn_state', 'local_orig', 'local_resp', 'missed_bytes',
    'history', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes',
    'tunnel_parents', 'label', 'detailed-label'
]
# æ¶ˆé™¤ Pandas è­¦å‘Š
pd.set_option('future.no_silent_downcasting', True)


def get_label_id(label_str):
    """
    é²æ£’çš„æ ‡ç­¾åŒ¹é…é€»è¾‘
    """
    s = str(label_str).lower()
    # ä¼˜å…ˆåŒ¹é…å…·ä½“æ”»å‡»
    if 'okiru' in s: return 4
    if 'ddos' in s: return 1
    if 'portscan' in s: return 2
    if 'c&c' in s or 'botnet' in s or 'heartbeat' in s: return 3
    if 'attack' in s or 'malware' in s or 'virus' in s: return 4

    # æœ€ååŒ¹é…è‰¯æ€§
    if 'benign' in s: return 0

    # å¦‚æœåŒ…å« malicious ä½†æ²¡æœ‰å…·ä½“ç»†åˆ†ï¼Œå½’ä¸º 4
    if 'malicious' in s: return 4

    return 0


def clean_and_convert(df):
    if df.empty: return pd.DataFrame()

    # === [å…³é”®ä¿®å¤] æ ‡ç­¾æå–é€»è¾‘ ===
    # ä¸ä¾èµ–åˆ—åï¼Œå¼ºåˆ¶å–æœ€å 3 åˆ—å¹¶å°†å®ƒä»¬æ‹¼æˆä¸€ä¸ªå­—ç¬¦ä¸²
    # è¿™æ ·æ— è®ºæ•°æ®æ˜¯ "-   Malicious   Okiru" è¿˜æ˜¯åˆ†å¼€çš„ tabï¼Œéƒ½èƒ½è¢«æ•è·

    # å–æœ€å3åˆ—ï¼ˆé˜²æ­¢è¶Šç•Œï¼Œå¦‚æœåˆ—æ•°ä¸å¤Ÿå°±å–å…¨éƒ¨ï¼‰
    last_cols = df.iloc[:, -3:].astype(str)

    # å°†è¿™å‡ åˆ—çš„å†…å®¹ç”¨ç©ºæ ¼æ‹¼èµ·æ¥
    df['combined_search_text'] = last_cols.apply(lambda x: ' '.join(x), axis=1)

    # åº”ç”¨æ ‡ç­¾åŒ¹é…
    df['label'] = df['combined_search_text'].apply(get_label_id)

    # === ä¸‹é¢æ˜¯å¸¸è§„æ¸…æ´—é€»è¾‘ ===
    df = df.replace({'-': 0, '(empty)': 0}).infer_objects(copy=False)

    num_cols = ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes',
                'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes']
    for c in num_cols:
        # å¦‚æœåˆ—åä¸å¯¹é½ï¼Œå¯èƒ½æŸäº›ç‰¹å¾ä¼šåœ¨æœ€åå‡ åˆ—ï¼Œè¿™é‡Œåšä¸ªå…œåº•
        if c not in df.columns:
            df[c] = 0.0
        else:
            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)

    df['proto'] = df['proto'].astype(str).map(lambda x: PROTO_MAP.get(x.lower(), 6))
    df['conn_state'] = df['conn_state'].astype(str).map(lambda x: STATE_MAP.get(x, 13))

    # é€‰å–æœ€ç»ˆç‰¹å¾
    df = df[FEATURE_COLS + ['label']]
    df = df.astype(np.float32)
    df['label'] = df['label'].astype(np.int8)

    return df


def process_file_with_quota(args):
    file_path, shared_counts, lock = args
    CHUNK_SIZE = 1_000_000
    final_dfs = []

    try:
        # å³ä½¿åˆ—å¯¹ä¸é½ï¼Œæˆ‘ä»¬ä¹ŸæŒ‰ 23 åˆ—è¯»ï¼Œåæ­£æˆ‘ä»¬åªå…³å¿ƒå‰å‡ åˆ—ç‰¹å¾å’Œæœ€åå‡ åˆ—æ ‡ç­¾
        # ä½¿ç”¨ names=COL_NAMES_23 ä¼šå¼ºåˆ¶ Pandas æ‰©å±•åˆ—ï¼Œä¸å¤Ÿçš„è¡¥ NaNï¼Œè¿™å¯¹æˆ‘ä»¬å¾ˆæœ‰åˆ©
        reader = pd.read_csv(
            file_path, sep='\t', comment='#', names=COL_NAMES_23,
            chunksize=CHUNK_SIZE,
            low_memory=False, quoting=csv.QUOTE_NONE, on_bad_lines='skip'  # å¿½ç•¥åè¡Œ
        )

        for chunk_df in reader:
            cleaned_chunk = clean_and_convert(chunk_df)
            if cleaned_chunk.empty: continue

            # åˆ†ç»„ç­›é€‰
            groups = cleaned_chunk.groupby('label')

            with lock:
                for label, group_df in groups:
                    label = int(label)
                    current_count = shared_counts.get(label, 0)

                    if current_count >= MAX_SAMPLES_PER_CLASS:
                        continue

                    needed = MAX_SAMPLES_PER_CLASS - current_count
                    to_take = group_df.iloc[:needed]

                    shared_counts[label] = current_count + len(to_take)
                    final_dfs.append(to_take)

        if not final_dfs: return None
        return pd.concat(final_dfs)

    except Exception:
        return None


def main():
    if os.path.exists(OUTPUT_CSV): os.remove(OUTPUT_CSV)

    files = glob.glob(os.path.join(DATASET_ROOT, '**', 'conn.log.labeled'), recursive=True)
    if not files:
        print("æœªæ‰¾åˆ°æ–‡ä»¶")
        return

    print(f"ğŸš€ å¯åŠ¨ç»ˆæä¿®å¤ç‰ˆ (Smart Label Detection)")
    print(f"ğŸ¯ æ¯ç±»é…é¢: {MAX_SAMPLES_PER_CLASS}")

    pd.DataFrame(columns=FEATURE_COLS + ['label']).to_csv(OUTPUT_CSV, index=False)

    manager = multiprocessing.Manager()
    shared_counts = manager.dict({0: 0, 1: 0, 2: 0, 3: 0, 4: 0})
    lock = manager.Lock()

    tasks = [(f, shared_counts, lock) for f in files]

    # é™åˆ¶å¹¶å‘ï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸
    SAFE_WORKERS = 4

    with ProcessPoolExecutor(max_workers=SAFE_WORKERS) as executor:
        futures = {executor.submit(process_file_with_quota, task): task for task in tasks}

        pbar = tqdm(as_completed(futures), total=len(files), desc="Processing")

        for future in pbar:
            try:
                result_df = future.result()
                current_stats = dict(shared_counts)
                # åŠ¨æ€æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix(
                    Benign=f"{current_stats[0] // 1000}k",
                    DDoS=f"{current_stats[1] // 1000}k",
                    PortScan=f"{current_stats[2] // 1000}k",
                    C_C=f"{current_stats[3]}",
                    Malware=f"{current_stats[4] // 1000}k"
                )

                if result_df is not None and not result_df.empty:
                    result_df.to_csv(OUTPUT_CSV, mode='a', header=False, index=False)
                    del result_df
            except Exception as e:
                pass

    print("\n" + "=" * 50)
    print(f"âœ… å¤„ç†å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡: {dict(shared_counts)}")
    print("=" * 50)


if __name__ == '__main__':
    multiprocessing.freeze_support()
    main()